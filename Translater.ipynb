{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "new-translater.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Нейронная сеть для перевода описания на русский язык. В основе её архитектуры  использована модель трансформера. Как и стандартные языковые модели, модель нейросети-переводчика состоит из кодировщика и декодера. Кодировщик, получая тензор, соответствующий заголовку описания изображения на английском языке, не сжимает все исходное предложение в один контекстный вектор, а создает последовательность контекстных векторов, каждый из которых видит все токены во всех позициях во входной последовательности. После этого декодер декодирует их для вывода итогового предложения на русском языке."
      ],
      "metadata": {
        "id": "v4MT60Sgm5l0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт библиотек"
      ],
      "metadata": {
        "id": "DLxLetXamrzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:28:03.462973Z",
          "iopub.execute_input": "2022-05-31T10:28:03.463341Z",
          "iopub.status.idle": "2022-05-31T10:28:24.781165Z",
          "shell.execute_reply.started": "2022-05-31T10:28:03.463313Z",
          "shell.execute_reply": "2022-05-31T10:28:24.780121Z"
        },
        "trusted": true,
        "id": "yu8Wxk3_mrzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:28:24.783077Z",
          "iopub.execute_input": "2022-05-31T10:28:24.783369Z",
          "iopub.status.idle": "2022-05-31T10:28:49.176421Z",
          "shell.execute_reply.started": "2022-05-31T10:28:24.783341Z",
          "shell.execute_reply": "2022-05-31T10:28:49.175454Z"
        },
        "trusted": true,
        "id": "EMGye5_Lmrzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:28:49.181236Z",
          "iopub.execute_input": "2022-05-31T10:28:49.181675Z",
          "iopub.status.idle": "2022-05-31T10:29:08.954093Z",
          "shell.execute_reply.started": "2022-05-31T10:28:49.181631Z",
          "shell.execute_reply": "2022-05-31T10:29:08.953102Z"
        },
        "trusted": true,
        "id": "LzqRuxG8mrzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import spacy\n",
        "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
        "spacy_rus = spacy.load(\"ru_core_news_sm\")\n",
        "\n",
        "import random\n",
        "import time\n",
        "import math"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:29:08.955616Z",
          "iopub.execute_input": "2022-05-31T10:29:08.956006Z",
          "iopub.status.idle": "2022-05-31T10:29:16.417554Z",
          "shell.execute_reply.started": "2022-05-31T10:29:08.955943Z",
          "shell.execute_reply": "2022-05-31T10:29:16.41668Z"
        },
        "trusted": true,
        "id": "HajV9WsWmrzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:31:29.545167Z",
          "iopub.execute_input": "2022-05-31T10:31:29.545584Z",
          "iopub.status.idle": "2022-05-31T10:31:29.554375Z",
          "shell.execute_reply.started": "2022-05-31T10:31:29.545539Z",
          "shell.execute_reply": "2022-05-31T10:31:29.553612Z"
        },
        "trusted": true,
        "id": "URa5V3Ykmrzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.set_device(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:31:29.556037Z",
          "iopub.execute_input": "2022-05-31T10:31:29.55696Z",
          "iopub.status.idle": "2022-05-31T10:31:29.567263Z",
          "shell.execute_reply.started": "2022-05-31T10:31:29.55692Z",
          "shell.execute_reply": "2022-05-31T10:31:29.566504Z"
        },
        "trusted": true,
        "id": "oW-J21hamrzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка данных"
      ],
      "metadata": {
        "id": "wc3EaFaimrzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Словари"
      ],
      "metadata": {
        "id": "SUW7csk1mrzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VocabularyEN:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.itos = dict()#{0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi = dict()#{v: k for k, v in self.itos.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    def load_vocab(self):\n",
        "        with open('itos_en.txt') as itos:\n",
        "            for i in itos.readlines():\n",
        "                key, val = i.strip().split('|', maxsplit=1)\n",
        "                self.itos[int(key)] = val\n",
        "        with open('stoi_en.txt') as stoi:\n",
        "            for i in stoi.readlines():\n",
        "                key, val = i.strip().split('|', maxsplit=1)\n",
        "                self.stoi[key] = int(val)\n",
        "                \n",
        "    def tokenize(self,text):\n",
        "        return [token.text.lower() for token in spacy_eng.tokenizer(text)]\n",
        "    \n",
        "    def numericalize(self,text):\n",
        "        \"\"\" For each word in the text corresponding index token for that word form the vocab built as list \"\"\"\n",
        "        tokenized_text = self.tokenize(text)\n",
        "        return [self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokenized_text]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:24.649109Z",
          "iopub.execute_input": "2022-05-31T10:36:24.649942Z",
          "iopub.status.idle": "2022-05-31T10:36:24.660343Z",
          "shell.execute_reply.started": "2022-05-31T10:36:24.649905Z",
          "shell.execute_reply": "2022-05-31T10:36:24.659418Z"
        },
        "trusted": true,
        "id": "mKcsq4q4mrzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VocabularyRU:\n",
        "    def __init__(self,freq_threshold=5):\n",
        "        #setting the pre-reserved tokens int to string tokens\n",
        "        self.itos = {0:\"<PAD>\",1:\"<SOS>\",2:\"<EOS>\",3:\"<UNK>\"}\n",
        "        \n",
        "        #string to int tokens\n",
        "        #its reverse dict self.itos\n",
        "        self.stoi = {v:k for k,v in self.itos.items()}\n",
        "        \n",
        "        self.freq_threshold = freq_threshold\n",
        "        \n",
        "    def __len__(self): return len(self.itos)\n",
        "    \n",
        "    @staticmethod\n",
        "    def tokenize(text):\n",
        "        return [token.text.lower() for token in spacy_rus.tokenizer(text)]\n",
        "    \n",
        "    def build_vocab(self, sentence_list):\n",
        "        frequencies = Counter()\n",
        "        idx = 4\n",
        "        \n",
        "        for sentence in sentence_list:\n",
        "            for word in self.tokenize(sentence):\n",
        "                frequencies[word] += 1\n",
        "                \n",
        "                if frequencies[word] == self.freq_threshold:\n",
        "                    self.stoi[word] = idx\n",
        "                    self.itos[idx] = word\n",
        "                    idx += 1\n",
        "\n",
        "    def numericalize(self,text):\n",
        "        tokenized_text = self.tokenize(text)\n",
        "        return [self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokenized_text]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:25.170958Z",
          "iopub.execute_input": "2022-05-31T10:36:25.17321Z",
          "iopub.status.idle": "2022-05-31T10:36:25.182894Z",
          "shell.execute_reply.started": "2022-05-31T10:36:25.173176Z",
          "shell.execute_reply": "2022-05-31T10:36:25.182034Z"
        },
        "trusted": true,
        "id": "eMB2ao5amrzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание Датасета и Даталоадера"
      ],
      "metadata": {
        "id": "Xlh-KOORmrzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        " \n",
        "    def __init__(self,is_train=True):\n",
        "        self.captions_en = []\n",
        "        self.captions_ru = []\n",
        "        if is_train:\n",
        "            path_ru = r'cap_ru_train.txt'\n",
        "            path_en = r'cap_en_train.txt'\n",
        "        else:\n",
        "            path_ru = r'cap_ru_valid.txt'\n",
        "            path_en = r'cap_en_valid.txt'\n",
        "        with open(path_en, \"r\") as cap_en:\n",
        "            for line in cap_en.readlines():\n",
        "                self.captions_en.append(line.replace(\"\\n\",\"\"))\n",
        "        \n",
        "        with open(path_ru, \"r\") as cap_en:\n",
        "            for line in cap_en.readlines():\n",
        "                self.captions_ru.append(line.replace(\"\\n\",\"\"))\n",
        "        \n",
        "        #Initialize vocabulary and build vocab\n",
        "        self.vocab_en = VocabularyEN()\n",
        "        self.vocab_en.load_vocab()\n",
        "\n",
        "        self.captions_ru_all = []\n",
        "        with open('cap_ru_all.txt', \"r\") as cap_ru_all:\n",
        "            for line in cap_ru_all.readlines():\n",
        "                self.captions_ru_all.append(line.replace(\"\\n\",\"\"))\n",
        "        self.vocab_ru = VocabularyRU()\n",
        "        self.vocab_ru.build_vocab(self.captions_ru_all)\n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.captions_ru)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        caption_en = self.captions_en[idx]\n",
        "        caption_ru = self.captions_ru[idx]\n",
        "                \n",
        "        #numericalize the caption text\n",
        "        caption_vec_en = []\n",
        "        caption_vec_en += [self.vocab_en.stoi[\"<SOS>\"]]\n",
        "        caption_vec_en += self.vocab_en.numericalize(caption_en)\n",
        "        caption_vec_en += [self.vocab_en.stoi[\"<EOS>\"]]\n",
        "        \n",
        "        caption_vec_ru = []\n",
        "        caption_vec_ru += [self.vocab_ru.stoi[\"<SOS>\"]]\n",
        "        caption_vec_ru += self.vocab_ru.numericalize(caption_ru)\n",
        "        caption_vec_ru += [self.vocab_ru.stoi[\"<EOS>\"]]\n",
        "        \n",
        "        #return torch.tensor(caption_vec_en[::-1]), torch.tensor(caption_vec_ru)\n",
        "        return torch.tensor(caption_vec_en), torch.tensor(caption_vec_ru)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:26.299743Z",
          "iopub.execute_input": "2022-05-31T10:36:26.300404Z",
          "iopub.status.idle": "2022-05-31T10:36:26.312285Z",
          "shell.execute_reply.started": "2022-05-31T10:36:26.300367Z",
          "shell.execute_reply": "2022-05-31T10:36:26.311517Z"
        },
        "trusted": true,
        "id": "H__FKUeZmrzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CapsCollate:\n",
        " \n",
        "    def __init__(self,pad_idx_en,pad_idx_ru,batch_first=False):\n",
        "        self.pad_idx_en = pad_idx_en\n",
        "        self.pad_idx_ru = pad_idx_ru\n",
        "        self.batch_first = batch_first\n",
        "    \n",
        "    def __call__(self,batch):\n",
        "        trg_en = [item[0] for item in batch]\n",
        "        trg_en = pad_sequence(trg_en, batch_first=self.batch_first, padding_value=self.pad_idx_en)\n",
        "        \n",
        "        trg_ru = [item[1] for item in batch]\n",
        "        trg_ru = pad_sequence(trg_ru, batch_first=self.batch_first, padding_value=self.pad_idx_ru)\n",
        "        \n",
        "        return trg_en,trg_ru"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:26.643183Z",
          "iopub.execute_input": "2022-05-31T10:36:26.643614Z",
          "iopub.status.idle": "2022-05-31T10:36:26.652275Z",
          "shell.execute_reply.started": "2022-05-31T10:36:26.643572Z",
          "shell.execute_reply": "2022-05-31T10:36:26.651496Z"
        },
        "trusted": true,
        "id": "Gz75INcEmrzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset,batch_size,shuffle=False,num_workers=1):\n",
        "    pad_idx_en = dataset.vocab_en.stoi[\"<PAD>\"]\n",
        "    pad_idx_ru = dataset.vocab_ru.stoi[\"<PAD>\"]\n",
        "\n",
        "    collate_fn=CapsCollate(pad_idx_en=pad_idx_en,pad_idx_ru=pad_idx_ru,batch_first=True)\n",
        "\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=num_workers,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    return data_loader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:27.081183Z",
          "iopub.execute_input": "2022-05-31T10:36:27.081481Z",
          "iopub.status.idle": "2022-05-31T10:36:27.087291Z",
          "shell.execute_reply.started": "2022-05-31T10:36:27.081454Z",
          "shell.execute_reply": "2022-05-31T10:36:27.086555Z"
        },
        "trusted": true,
        "id": "mC_8-UY6mrzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = Dataset(is_train=True)\n",
        "dataset_valid = Dataset(is_train=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:27.555247Z",
          "iopub.execute_input": "2022-05-31T10:36:27.555546Z",
          "iopub.status.idle": "2022-05-31T10:36:29.885251Z",
          "shell.execute_reply.started": "2022-05-31T10:36:27.555521Z",
          "shell.execute_reply": "2022-05-31T10:36:29.884418Z"
        },
        "trusted": true,
        "id": "_l2i-I2Gmrzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#writing the dataloaders\n",
        "#setting the constants\n",
        "BATCH_SIZE = 256\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "data_loader_train = get_data_loader(dataset_train, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "data_loader_valid = get_data_loader(dataset_valid, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:29.887043Z",
          "iopub.execute_input": "2022-05-31T10:36:29.887345Z",
          "iopub.status.idle": "2022-05-31T10:36:29.895262Z",
          "shell.execute_reply.started": "2022-05-31T10:36:29.887319Z",
          "shell.execute_reply": "2022-05-31T10:36:29.894511Z"
        },
        "trusted": true,
        "id": "JzH3zaQwmrzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка работы Даталоадера"
      ],
      "metadata": {
        "id": "YK5G5rT1mrzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(data_loader_train)\n",
        "batch = next(dataiter)\n",
        "caption_en, caption_ru = batch\n",
        "\n",
        "for i in range(BATCH_SIZE):\n",
        "    cap_en,cap_ru = caption_en[i],caption_ru[i]\n",
        "    caption_label_en = [dataset_train.vocab_en.itos[token] for token in cap_en.tolist()]\n",
        "    eos_index_en = caption_label_en.index('<EOS>')\n",
        "    caption_label_en = caption_label_en[1:eos_index_en]\n",
        "    caption_label_en = ' '.join(caption_label_en)\n",
        "    \n",
        "    caption_label_ru = [dataset_train.vocab_ru.itos[token] for token in cap_ru.tolist()]\n",
        "    eos_index_ru = caption_label_ru.index('<EOS>')\n",
        "    caption_label_ru = caption_label_ru[1:eos_index_ru]\n",
        "    caption_label_ru = ' '.join(caption_label_ru) \n",
        "\n",
        "    print(caption_label_en, caption_label_ru)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:29.896864Z",
          "iopub.execute_input": "2022-05-31T10:36:29.897231Z",
          "iopub.status.idle": "2022-05-31T10:36:30.416853Z",
          "shell.execute_reply.started": "2022-05-31T10:36:29.897196Z",
          "shell.execute_reply": "2022-05-31T10:36:30.415678Z"
        },
        "trusted": true,
        "id": "fL-QXYuUmrzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание модели"
      ],
      "metadata": {
        "id": "_-VuKwKUmrzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Слой внимания \"с несколькими головами\""
      ],
      "metadata": {
        "id": "fzXqrZcJmrzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "                        \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "                        \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "                    \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "              \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:31.323081Z",
          "iopub.execute_input": "2022-05-31T10:36:31.323499Z",
          "iopub.status.idle": "2022-05-31T10:36:31.338373Z",
          "shell.execute_reply.started": "2022-05-31T10:36:31.323451Z",
          "shell.execute_reply": "2022-05-31T10:36:31.337641Z"
        },
        "trusted": true,
        "id": "8IMJT_nTmrzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Слой Position-wise Feedforward"
      ],
      "metadata": {
        "id": "NbfbMAfbmrzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:31.99705Z",
          "iopub.execute_input": "2022-05-31T10:36:31.997642Z",
          "iopub.status.idle": "2022-05-31T10:36:32.004323Z",
          "shell.execute_reply.started": "2022-05-31T10:36:31.997602Z",
          "shell.execute_reply": "2022-05-31T10:36:32.003197Z"
        },
        "trusted": true,
        "id": "uyO5mRxAmrzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Слой кодировщика"
      ],
      "metadata": {
        "id": "ndu0fuXOmrzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        _src = self.self_attention(src, src, src, src_mask)        \n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))        \n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        return src"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:32.545273Z",
          "iopub.execute_input": "2022-05-31T10:36:32.545632Z",
          "iopub.status.idle": "2022-05-31T10:36:32.553696Z",
          "shell.execute_reply.started": "2022-05-31T10:36:32.545582Z",
          "shell.execute_reply": "2022-05-31T10:36:32.552915Z"
        },
        "trusted": true,
        "id": "wLv0LqW4mrzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кодировщик"
      ],
      "metadata": {
        "id": "fA2w73m3mrzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "                \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        src = self.dropout((self.tok_embedding(src.to(device)) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        \n",
        "        return src"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:33.070606Z",
          "iopub.execute_input": "2022-05-31T10:36:33.07105Z",
          "iopub.status.idle": "2022-05-31T10:36:33.081453Z",
          "shell.execute_reply.started": "2022-05-31T10:36:33.071023Z",
          "shell.execute_reply": "2022-05-31T10:36:33.080618Z"
        },
        "trusted": true,
        "id": "yDZQKM8Gmrzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Слой декодера"
      ],
      "metadata": {
        "id": "LqBVfvw-mrzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        _trg = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))        \n",
        "        _trg = self.encoder_attention(trg, enc_src, enc_src, src_mask)  \n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))                    \n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))]\n",
        "        \n",
        "        return trg"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:33.601869Z",
          "iopub.execute_input": "2022-05-31T10:36:33.602151Z",
          "iopub.status.idle": "2022-05-31T10:36:33.611548Z",
          "shell.execute_reply.started": "2022-05-31T10:36:33.602127Z",
          "shell.execute_reply": "2022-05-31T10:36:33.610654Z"
        },
        "trusted": true,
        "id": "Be67guZCmrzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Декодер"
      ],
      "metadata": {
        "id": "lPr0_m8bmrzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        trg = self.dropout((self.tok_embedding(trg.to(self.device)) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:34.247548Z",
          "iopub.execute_input": "2022-05-31T10:36:34.249958Z",
          "iopub.status.idle": "2022-05-31T10:36:34.267303Z",
          "shell.execute_reply.started": "2022-05-31T10:36:34.249912Z",
          "shell.execute_reply": "2022-05-31T10:36:34.26639Z"
        },
        "trusted": true,
        "id": "MTdetLEKmrzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Языковая модель"
      ],
      "metadata": {
        "id": "3iukCdV3mrzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2).to(self.device)\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        trg_len = trg.shape[1]        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        trg_mask = trg_pad_mask.to(self.device) & trg_sub_mask.to(self.device)\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:35.221234Z",
          "iopub.execute_input": "2022-05-31T10:36:35.221721Z",
          "iopub.status.idle": "2022-05-31T10:36:35.236029Z",
          "shell.execute_reply.started": "2022-05-31T10:36:35.221678Z",
          "shell.execute_reply": "2022-05-31T10:36:35.235233Z"
        },
        "trusted": true,
        "id": "vCNJNk3Mmrzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание экземпляра модели"
      ],
      "metadata": {
        "id": "zL9xl3-4mrz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(dataset_train.vocab_en)\n",
        "OUTPUT_DIM = len(dataset_train.vocab_ru)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 4\n",
        "DEC_HEADS = 4\n",
        "ENC_PF_DIM = 256\n",
        "DEC_PF_DIM = 256\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "PAD_IDX = dataset_train.vocab_en.stoi['<PAD>']\n",
        "SOS_IDX = dataset_train.vocab_ru.stoi['<SOS>']\n",
        "EOS_IDX = dataset_train.vocab_ru.stoi['<EOS>']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:38.619342Z",
          "iopub.execute_input": "2022-05-31T10:36:38.619748Z",
          "iopub.status.idle": "2022-05-31T10:36:38.626583Z",
          "shell.execute_reply.started": "2022-05-31T10:36:38.619718Z",
          "shell.execute_reply": "2022-05-31T10:36:38.625511Z"
        },
        "trusted": true,
        "id": "p4YbSJKcmrz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = Encoder(INPUT_DIM, HID_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
        "dec = Decoder(OUTPUT_DIM, HID_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
        "\n",
        "SRC_PAD_IDX = dataset_train.vocab_en.stoi['<PAD>']\n",
        "TRG_PAD_IDX = dataset_train.vocab_ru.stoi['<PAD>']\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:36:39.824807Z",
          "iopub.execute_input": "2022-05-31T10:36:39.825455Z",
          "iopub.status.idle": "2022-05-31T10:36:47.951376Z",
          "shell.execute_reply.started": "2022-05-31T10:36:39.825424Z",
          "shell.execute_reply": "2022-05-31T10:36:47.950566Z"
        },
        "trusted": true,
        "id": "wBqEjAWLmrz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T11:51:23.555529Z",
          "iopub.execute_input": "2022-05-29T11:51:23.555957Z",
          "iopub.status.idle": "2022-05-29T11:51:23.561841Z",
          "shell.execute_reply.started": "2022-05-29T11:51:23.555927Z",
          "shell.execute_reply": "2022-05-29T11:51:23.561037Z"
        },
        "trusted": true,
        "id": "fGzhuyQ6mrz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.05)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T11:51:23.869191Z",
          "iopub.execute_input": "2022-05-29T11:51:23.870017Z",
          "iopub.status.idle": "2022-05-29T11:51:23.89645Z",
          "shell.execute_reply.started": "2022-05-29T11:51:23.869982Z",
          "shell.execute_reply": "2022-05-29T11:51:23.895683Z"
        },
        "trusted": true,
        "id": "qSRVvgZjmrz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T11:51:24.158151Z",
          "iopub.execute_input": "2022-05-29T11:51:24.158533Z",
          "iopub.status.idle": "2022-05-29T11:51:24.164211Z",
          "shell.execute_reply.started": "2022-05-29T11:51:24.158489Z",
          "shell.execute_reply": "2022-05-29T11:51:24.163416Z"
        },
        "trusted": true,
        "id": "On80pnr-mrz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение и оценка"
      ],
      "metadata": {
        "id": "urRMavc9mrz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch[0]        \n",
        "        trg = batch[1]\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if int(len(batch[0])) == BATCH_SIZE:\n",
        "            output = model(src, trg[:,:-1])                \n",
        "            output_dim = output.shape[-1]            \n",
        "            output = output.view(-1, output_dim)            \n",
        "            trg = trg[:,1:].contiguous().view(-1).to(device)\n",
        "                \n",
        "            if epoch_loss == 0:\n",
        "                print(\" \".join([dataset_train.vocab_ru.itos[token] for token in output.argmax(1).tolist()[:25]]))\n",
        "                print(\" \".join([dataset_train.vocab_ru.itos[token] for token in trg.tolist()[:25]]))\n",
        "            \n",
        "            loss = criterion(output, trg)        \n",
        "            loss.backward()                \n",
        "            optimizer.step()        \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T11:51:24.957123Z",
          "iopub.execute_input": "2022-05-29T11:51:24.958073Z",
          "iopub.status.idle": "2022-05-29T11:51:24.969249Z",
          "shell.execute_reply.started": "2022-05-29T11:51:24.958032Z",
          "shell.execute_reply": "2022-05-29T11:51:24.968466Z"
        },
        "trusted": true,
        "id": "iKCq1HPXmrz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch[0]\n",
        "            trg = batch[1]\n",
        "\n",
        "            if int(len(batch[0])) == BATCH_SIZE:\n",
        "                output = model(src, trg[:,:-1])                \n",
        "                output_dim = output.shape[-1]\n",
        "                output = output.contiguous().view(-1, output_dim)                \n",
        "                trg = trg[:,1:].contiguous().view(-1)\n",
        "                loss = criterion(output, trg.to(device))\n",
        "                epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T11:51:29.780657Z",
          "iopub.execute_input": "2022-05-29T11:51:29.78104Z",
          "iopub.status.idle": "2022-05-29T11:51:29.789262Z",
          "shell.execute_reply.started": "2022-05-29T11:51:29.781004Z",
          "shell.execute_reply": "2022-05-29T11:51:29.788277Z"
        },
        "trusted": true,
        "id": "qLiEjJBvmrz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T11:51:31.50977Z",
          "iopub.execute_input": "2022-05-29T11:51:31.510473Z",
          "iopub.status.idle": "2022-05-29T11:51:31.515535Z",
          "shell.execute_reply.started": "2022-05-29T11:51:31.510437Z",
          "shell.execute_reply": "2022-05-29T11:51:31.514701Z"
        },
        "trusted": true,
        "id": "EUMUQyx6mrz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 30\n",
        "CLIP = 1\n",
        "date = '29-05'\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "k = 0\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    train_iterator = iter(data_loader_train)\n",
        "    valid_iterator = iter(data_loader_valid)\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        name = 'translater_' + date + '-' + str(k) + '.pt'\n",
        "        k += 1\n",
        "        torch.save(model.state_dict(), name)\n",
        "        saved_best_model = True\n",
        "    else:\n",
        "        saved_best_model = False\n",
        "    \n",
        "    print('Epoch: {:02} Time: {}m {}s | Train: Loss = {:.7f}  | Val: Loss = {:.7f}  | SAVE = {}'.format(\n",
        "         epoch+1,\n",
        "         epoch_mins,\n",
        "         epoch_secs,\n",
        "         train_loss,\n",
        "         valid_loss,\n",
        "         saved_best_model))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T13:08:55.822834Z",
          "iopub.execute_input": "2022-05-29T13:08:55.823267Z",
          "iopub.status.idle": "2022-05-29T14:57:56.359704Z",
          "shell.execute_reply.started": "2022-05-29T13:08:55.823235Z",
          "shell.execute_reply": "2022-05-29T14:57:56.358566Z"
        },
        "trusted": true,
        "id": "jaTQJjB0mrz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_best = 'translater_' + date + '-' + str(0) + '.pt'\n",
        "torch.save(model.state_dict(), name_best)\n",
        "model_loaded = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "model_loaded.load_state_dict(torch.load(name_best))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T11:38:25.039274Z",
          "iopub.execute_input": "2022-05-29T11:38:25.039684Z",
          "iopub.status.idle": "2022-05-29T11:38:25.32727Z",
          "shell.execute_reply.started": "2022-05-29T11:38:25.03965Z",
          "shell.execute_reply": "2022-05-29T11:38:25.32642Z"
        },
        "trusted": true,
        "id": "CzvxGj3Nmrz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(r'translater_29-05-1.pt'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:37:27.085611Z",
          "iopub.execute_input": "2022-05-31T10:37:27.086323Z",
          "iopub.status.idle": "2022-05-31T10:37:27.721521Z",
          "shell.execute_reply.started": "2022-05-31T10:37:27.086286Z",
          "shell.execute_reply": "2022-05-31T10:37:27.72078Z"
        },
        "trusted": true,
        "id": "eLwovzlSmrz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка"
      ],
      "metadata": {
        "id": "jaliS7mBmrz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, model, device, max_len = 25):\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    caption_vec_en = []\n",
        "    caption_vec_en += [dataset_train.vocab_en.stoi[\"<SOS>\"]]\n",
        "    caption_vec_en += dataset_train.vocab_en.numericalize(sentence)\n",
        "    caption_vec_en += [dataset_train.vocab_en.stoi[\"<EOS>\"]]\n",
        "\n",
        "    src_tensor = torch.LongTensor(caption_vec_en).unsqueeze(0).to(device) \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [dataset_train.vocab_ru.stoi[\"<SOS>\"]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == dataset_train.vocab_ru.stoi[\"<EOS>\"]:\n",
        "            break\n",
        "    \n",
        "    caption_label_ru = [dataset_train.vocab_ru.itos[token] for token in trg_indexes]\n",
        "    \n",
        "    return caption_label_ru[1:]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:37:32.864809Z",
          "iopub.execute_input": "2022-05-31T10:37:32.865675Z",
          "iopub.status.idle": "2022-05-31T10:37:32.875707Z",
          "shell.execute_reply.started": "2022-05-31T10:37:32.865563Z",
          "shell.execute_reply": "2022-05-31T10:37:32.874658Z"
        },
        "trusted": true,
        "id": "11iSpNn1mrz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = ['A computer desk with a laptop and a keyboard.',\n",
        "       \"A woman is cooking a dinner\",\n",
        "       \"A refrigerator with a bunch of food on it\",\n",
        "       \"A group of people sitting on a train platform\", \n",
        "       \"A cookie sitting on top of a white plate.\",\n",
        "       \"A vintage stove and washing tub on a brick floor.\",\n",
        "       \"A man on a motorcycle is going down the street.\",\n",
        "       \"A man riding a motorcycle next to a lush green forest.\",\n",
        "       \"A person is riding a motorcycle down a country road.\",\n",
        "       \"A motorcyclist travels down a country two-lane highway.\",\n",
        "       \"a person riding a motorcycle on a road with trees\",\n",
        "       \"A smiling woman holding a baby has a camera in her hand.\",\n",
        "       \"a woman takes a photo of herself and her child.\"]\n",
        "\n",
        "for i in src:    \n",
        "    caption_label_ru = translate_sentence(i, model, device)\n",
        "    print(i, ' '.join(caption_label_ru[:-1]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T11:29:43.472191Z",
          "iopub.execute_input": "2022-05-29T11:29:43.472609Z",
          "iopub.status.idle": "2022-05-29T11:29:43.824681Z",
          "shell.execute_reply.started": "2022-05-29T11:29:43.472578Z",
          "shell.execute_reply": "2022-05-29T11:29:43.823681Z"
        },
        "trusted": true,
        "id": "bFUlRv3gmrz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(data_loader_valid)\n",
        "batch = next(dataiter)\n",
        "caption_en, caption_ru = batch\n",
        "\n",
        "for i in range(BATCH_SIZE):\n",
        "    cap_en,cap_ru = caption_en[i],caption_ru[i] \n",
        "    caption_label_en = [dataset_train.vocab_en.itos[token] for token in cap_en.tolist()]\n",
        "    eos_index_en = caption_label_en.index('<EOS>')\n",
        "    caption_label_en = caption_label_en[1:eos_index_en]\n",
        "    caption_label_en = ' '.join(caption_label_en)\n",
        "    caption_label_ru_tr = translate_sentence(caption_label_en, model, device)\n",
        "    \n",
        "    caption_label_ru = [dataset_train.vocab_ru.itos[token] for token in cap_ru.tolist()]\n",
        "    eos_index_ru = caption_label_ru.index('<EOS>')\n",
        "    caption_label_ru = caption_label_ru[1:eos_index_ru]\n",
        "    caption_label_ru = ' '.join(caption_label_ru) \n",
        "    \n",
        "    model_ru = ' '.join(caption_label_ru_tr[:-1])\n",
        "    print(\"CAPTION :\", caption_label_en, \"\\nGT :\", caption_label_ru, \"\\nTRANSLATION :\", model_ru, \"\\n----------------------------------------\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-29T11:32:51.514285Z",
          "iopub.execute_input": "2022-05-29T11:32:51.514689Z",
          "iopub.status.idle": "2022-05-29T11:33:00.425813Z",
          "shell.execute_reply.started": "2022-05-29T11:32:51.514651Z",
          "shell.execute_reply": "2022-05-29T11:33:00.424128Z"
        },
        "trusted": true,
        "id": "sn95HqVymrz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLEU"
      ],
      "metadata": {
        "id": "2EbAEbrQmrz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import nltk\n",
        "\n",
        "def calculate_bleu(data, model, device, max_len = 25):\n",
        "\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for i in range(len(data.captions_en)):\n",
        "        \n",
        "        src = data.captions_en[i]\n",
        "        trg = data.captions_ru[i]\n",
        "        pred_trg = translate_sentence_1(src, model, device, max_len)\n",
        "        pred_trg = pred_trg[:-1]        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "\n",
        "    return bleu_score(pred_trgs, trgs), nltk.translate.bleu_score.corpus_bleu(trgs, pred_trgs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:41:57.482456Z",
          "iopub.execute_input": "2022-05-31T10:41:57.48331Z",
          "iopub.status.idle": "2022-05-31T10:41:57.491447Z",
          "shell.execute_reply.started": "2022-05-31T10:41:57.483274Z",
          "shell.execute_reply": "2022-05-31T10:41:57.490644Z"
        },
        "trusted": true,
        "id": "U8bylpT-mrz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculate_bleu(dataset_valid, model, device, max_len = 25))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T10:41:58.162989Z",
          "iopub.execute_input": "2022-05-31T10:41:58.163887Z",
          "iopub.status.idle": "2022-05-31T12:19:14.24084Z",
          "shell.execute_reply.started": "2022-05-31T10:41:58.163846Z",
          "shell.execute_reply": "2022-05-31T12:19:14.240068Z"
        },
        "trusted": true,
        "id": "Dpd-gdSLmrz9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}